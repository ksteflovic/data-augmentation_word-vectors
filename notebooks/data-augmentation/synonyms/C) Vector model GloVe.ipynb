{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Corpus' from 'glove' (C:\\Users\\Kika\\anaconda3\\lib\\site-packages\\glove\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24188\\2843592116.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mglove\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGlove\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Corpus' from 'glove' (C:\\Users\\Kika\\anaconda3\\lib\\site-packages\\glove\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import time\n",
    "from statistics import mean, median\n",
    "\n",
    "import en_core_web_sm\n",
    "import gensim.utils\n",
    "import gensim.models.keyedvectors\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "from glove import Glove, Corpus\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "nltk.download('punkt')\n",
    "\n",
    "logging.basicConfig(format=\"%(message)s\")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Model Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Načítanie predspracovaných viet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vytvorenie vektorov pre NEUPRAVENÉ VETY = 0\n",
    "#Vytvorenie vektorov pre UPRAVENÉ VETY (o synonymá) = 1\n",
    "\n",
    "file = 0\n",
    "if file == 0:\n",
    "    file = \"sentences\"\n",
    "else:\n",
    "    file = \"sentences_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Načítanie viet\n",
    "with open(\"files/\"+file, \"rb\") as fp:   # Unpickling\n",
    "    sentences = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Vytvorenie slovných vektorov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_size = 200\n",
    "window_size = 7\n",
    "\n",
    "\n",
    "embeddings_index = dict()\n",
    "\n",
    "start = time.time()\n",
    "#Tréning slovných vektorov\n",
    "\n",
    "corpus = Corpus()\n",
    "corpus.fit(sentences, window=window_size)\n",
    "glove = Glove(\n",
    "            no_components=dimension_size,      # Veľkosť dimenzie výsledných slovných vektorov\n",
    "            learning_rate=0.05)                # Rýchlosť učenia\n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=4)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "\n",
    "words = set(list(glove.dictionary.keys()))\n",
    "for word in words:\n",
    "    embeddings_index[word] = glove.word_vectors[glove.dictionary[word]]\n",
    "    \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of words: 25735 , training time: 33.24569869041443\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of words:\",len(words),\", training time:\",(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Uloženie vektorov do BIN súboru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attribute count not present in KeyedVectors<vector_size=200, 25735 keys>; will store in internal index_to_key order\n"
     ]
    }
   ],
   "source": [
    "# konvertovanie slovníka do formátu KeyedVectors\n",
    "kv = KeyedVectors(vector_size=dimension_size)\n",
    "kv.add_vectors(list(embeddings_index.keys()), list(embeddings_index.values()))\n",
    "\n",
    "# uloženie slovníka do binárneho súboru\n",
    "kv.save_word2vec_format(\"files/model_GloVe_\"+\"dim_\"+str(dimension_size)+\"_\"+time.strftime(\"%Y%m%d%H%M\")+\"_\"+file+\".bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flight', 0.9181925058364868),\n",
       " ('jet', 0.9180074334144592),\n",
       " ('passenger', 0.91603022813797),\n",
       " ('bomb', 0.9080346822738647),\n",
       " ('crashed', 0.9069170951843262),\n",
       " ('airport', 0.9053643345832825),\n",
       " ('pilot', 0.9050325155258179),\n",
       " ('crash', 0.9040655493736267),\n",
       " ('train', 0.9030295014381409),\n",
       " ('burned', 0.9005767703056335)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Príklad pre podobnosť\n",
    "word2vec.wv.most_similar(\"plane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
