{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import time\n",
    "from statistics import mean, median\n",
    "\n",
    "import en_core_web_sm\n",
    "import gensim.utils\n",
    "import gensim.models.keyedvectors\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "nltk.download('punkt')\n",
    "\n",
    "logging.basicConfig(format=\"%(message)s\")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Model Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Načítanie predspracovaných viet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vytvorenie vektorov pre NEUPRAVENÉ VETY = 0\n",
    "#Vytvorenie vektorov pre UPRAVENÉ VETY (o synonymá) = 1\n",
    "\n",
    "file = 1\n",
    "if file == 0:\n",
    "    file = \"sentences\"\n",
    "else:\n",
    "    file = \"sentences_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Načítanie viet\n",
    "with open(\"files/\"+file, \"rb\") as fp:   # Unpickling\n",
    "    sentences = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Vytvorenie slovných vektorov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_size = 150\n",
    "window_size = 7\n",
    "model = 0  # Skipgram = 1, CBOW = 0\n",
    "\n",
    "\n",
    "embeddings_index = dict()\n",
    "\n",
    "start = time.time()\n",
    "#Tréning slovných vektorov\n",
    "    \n",
    "word2vec = Word2Vec(\n",
    "    sentences,\n",
    "    min_count=1,                      # Ignorovať slová, ktoré sa v korpuse nachádzajú menej ako min_count\n",
    "    vector_size=dimension_size,       # Veľkosť dimenzie výsledných slovných vektorov\n",
    "    sg = model,                       # Skipgram = 1, CBOW = 0\n",
    "    epochs=15, \n",
    "    window=window_size,               # Počeť kontextových slov\n",
    "    workers=6,\n",
    "    seed=7)\n",
    "        \n",
    "words = set(word2vec.wv.index_to_key)        \n",
    "for word in words:\n",
    "    embeddings_index[word] = word2vec.wv[word]  \n",
    "    \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of words: 25735 , training time: 13.980042219161987\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of words:\",len(word2vec.wv),\", training time:\",(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Uloženie vektorov do BIN súboru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attribute count not present in <gensim.models.keyedvectors.KeyedVectors object at 0x0000010941059220>; will store in internal index_to_key order\n"
     ]
    }
   ],
   "source": [
    "# konvertovanie slovníka do formátu KeyedVectors\n",
    "kv = KeyedVectors(vector_size=dimension_size)\n",
    "kv.add_vectors(list(embeddings_index.keys()), list(embeddings_index.values()))\n",
    "\n",
    "# uloženie slovníka do binárneho súboru\n",
    "a = \"CBOW\" if model == 0 else \"SKIPGRAM\"\n",
    "\n",
    "kv.save_word2vec_format(\"files/model_\"+a+\"_\"+\"dim_\"+str(dimension_size)+\"_\"+time.strftime(\"%Y%m%d%H%M\")+\"_\"+file+\".bin\", binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aeroplane', 0.8194882273674011),\n",
       " ('activated', 0.5351089239120483),\n",
       " ('plunged', 0.49997350573539734),\n",
       " ('eerie', 0.47463902831077576),\n",
       " ('arrange', 0.45845866203308105),\n",
       " ('emitted', 0.4536671042442322),\n",
       " ('coincidence', 0.44575566053390503),\n",
       " ('refueling', 0.4371525049209595),\n",
       " ('layover', 0.43532484769821167),\n",
       " ('pretended', 0.4346317648887634)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Príklad pre podobnosť\n",
    "word2vec.wv.most_similar(\"plane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
